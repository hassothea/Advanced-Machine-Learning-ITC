{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **TP7 - Dimensional Reduction**\n",
    "\n",
    "-----\n",
    "\n",
    "**Course**: Advanced Machine Learning <br>\n",
    "**Lecturer**: Sothea HAS, PhD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Objective:**  Dimensional reduction is useful when dealing with high-dimensional dataset. It can also be used in clustering and data analysis. We will explore its potential using our previous dataset of satellite images.\n",
    "\n",
    "- The `notebook` of this `TP` can be downloaded here: [TP7_Dimensional_Reduction.ipynb](https://hassothea.github.io/Advanced-Machine-Learning-ITC/TPs/TP7_Dimensional_Reduction.ipynb){target=\"_blank\"}.\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1. Satellite Image Segmentation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will explore in this TP the satellite image dataset available in kaggle repository: [Satellite Images](https://www.kaggle.com/datasets/mahmoudreda55/satellite-image-classification).\n",
    "\n",
    "\n",
    "**A. Dimensional reduction with PCA** \n",
    "\n",
    "- Load the assembled data and perform different clustering algorithms on the data.\n",
    "- Perform reduced/normalized PCA on this dataset. How many dimension should we keep to retain $90\\%$ variation of the data?\n",
    "- What's the percentage of variance explained by the first two dimensions?\n",
    "- Visualize the data in 2 dimensional space using `PCA`.\n",
    "- Based on the resulting graph, would it better to work with the first two PCs (PC1 and PC2)?\n",
    "- Perform clustering algorithm on these two PCs. Analyze the performance of clustering algorithm.\n",
    "- Implement some select models using PC1 and PC2 as inputs to predict the type of satellite images and report their performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**B. Dimensional reduction with $t$-SNE** \n",
    "\n",
    "- Visualize the data in 2 dimensional space using $t$-SNE.\n",
    "- Based on the resulting graph, would it better to work with the embedded features by $t$-SNE?\n",
    "- Perform clustering algorithm on these embedded features. Analyze the performance of clustering algorithm.\n",
    "- Implement some select models using the embedded features as inputs to predict the type of satellite images and report their performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C. Dimensional reduction with Johnson-Lindenstrauss Lemma**\n",
    "\n",
    "- Project images onto $d=2, 5, 10$ dimensional spaces (called them `X_JL2`, `X_JL5` and `X_JL10` respectively).\n",
    "- Perform clustering algorithm on these projected data. Analyze the performance of clustering algorithm for each case.\n",
    "- Implement some select models using the projected features as inputs to predict the type of satellite images and report their performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**D. Dimensional reduction with Autoencoder**\n",
    "\n",
    "- Bulid autoencoder to encode and reconstruct satellite images using your own designed architecture.\n",
    "- Visualize some of the original, embedded and reconstructed images side by side.\n",
    "- Perform clustering algorithm on the latent images of the network. Analyze the performance of clustering algorithm for each case.\n",
    "- Implement some select models using the latent encoded images as inputs to predict the type of satellite images and report their performances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. Revisit Spam dataset**\n",
    "\n",
    "**Task:** \n",
    "\n",
    "- Perform clustering algorithms on `Spam` dataset using projected data obtained from the most suitable dimensional reduction method. \n",
    "- Built models to classify whether an email is a spam or not using projected data from the most suitable dimensional reduction approach above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>make</th>\n",
       "      <th>address</th>\n",
       "      <th>all</th>\n",
       "      <th>num3d</th>\n",
       "      <th>our</th>\n",
       "      <th>over</th>\n",
       "      <th>remove</th>\n",
       "      <th>internet</th>\n",
       "      <th>order</th>\n",
       "      <th>...</th>\n",
       "      <th>charSemicolon</th>\n",
       "      <th>charRoundbracket</th>\n",
       "      <th>charSquarebracket</th>\n",
       "      <th>charExclamation</th>\n",
       "      <th>charDollar</th>\n",
       "      <th>charHash</th>\n",
       "      <th>capitalAve</th>\n",
       "      <th>capitalLong</th>\n",
       "      <th>capitalTotal</th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.778</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.756</td>\n",
       "      <td>61</td>\n",
       "      <td>278</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.048</td>\n",
       "      <td>5.114</td>\n",
       "      <td>101</td>\n",
       "      <td>1028</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.184</td>\n",
       "      <td>0.010</td>\n",
       "      <td>9.821</td>\n",
       "      <td>485</td>\n",
       "      <td>2259</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.137</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>3.537</td>\n",
       "      <td>40</td>\n",
       "      <td>191</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  make  address   all  num3d   our  over  remove  internet  order  ...  \\\n",
       "0   1  0.00     0.64  0.64    0.0  0.32  0.00    0.00      0.00   0.00  ...   \n",
       "1   2  0.21     0.28  0.50    0.0  0.14  0.28    0.21      0.07   0.00  ...   \n",
       "2   3  0.06     0.00  0.71    0.0  1.23  0.19    0.19      0.12   0.64  ...   \n",
       "3   4  0.00     0.00  0.00    0.0  0.63  0.00    0.31      0.63   0.31  ...   \n",
       "4   5  0.00     0.00  0.00    0.0  0.63  0.00    0.31      0.63   0.31  ...   \n",
       "\n",
       "   charSemicolon  charRoundbracket  charSquarebracket  charExclamation  \\\n",
       "0           0.00             0.000                0.0            0.778   \n",
       "1           0.00             0.132                0.0            0.372   \n",
       "2           0.01             0.143                0.0            0.276   \n",
       "3           0.00             0.137                0.0            0.137   \n",
       "4           0.00             0.135                0.0            0.135   \n",
       "\n",
       "   charDollar  charHash  capitalAve  capitalLong  capitalTotal  type  \n",
       "0       0.000     0.000       3.756           61           278  spam  \n",
       "1       0.180     0.048       5.114          101          1028  spam  \n",
       "2       0.184     0.010       9.821          485          2259  spam  \n",
       "3       0.000     0.000       3.537           40           191  spam  \n",
       "4       0.000     0.000       3.537           40           191  spam  \n",
       "\n",
       "[5 rows x 59 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = \"https://raw.githubusercontent.com/hassothea/MLcourses/main/data/spam.txt\"\n",
    "data = pd.read_csv(path, sep=\" \")\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "$^{\\text{ðŸ“š}}$ [Hinton and Roweis (2002)](https://www.cs.toronto.edu/~fritz/absps/sne.pdf){target=\"_blank\"}. <br>\n",
    "$^{\\text{ðŸ“š}}$ [Laurens, $t$-SNE Page](https://lvdmaaten.github.io/tsne/){target=\"_blank\"}. <br>\n",
    "$^{\\text{ðŸ“š}}$ [Satellite Images](https://www.kaggle.com/datasets/mahmoudreda55/satellite-image-classification){target=\"_blank\"}. <br>\n",
    "$^{\\text{ðŸ“š}}$ [van der Maaten and Hinton (2008), Visualizing Data using t-SNE](https://jmlr.org/papers/volume9/vandermaaten08a/vandermaaten08a.pdf){target=\"_blank\"}. <br>\n",
    "$^{\\text{ðŸ“š}}$ [Bank et al (2021), Autoencoder](https://arxiv.org/pdf/2003.05991){target=\"_blank\"}. <br>\n",
    "$^{\\text{ðŸ“š}}$ [Umberto Michelucci (2022), An Introduction to Autoencoders](https://arxiv.org/abs/2201.03898){target=\"_blank\"}."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
